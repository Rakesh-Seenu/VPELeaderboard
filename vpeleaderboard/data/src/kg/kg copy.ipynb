{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d877e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (24.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 12.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.3.1\n",
      "    Uninstalling pip-24.3.1:\n",
      "      Successfully uninstalled pip-24.3.1\n",
      "Successfully installed pip-25.1.1\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cabfec22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: torch in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch-geometric) (3.11.14)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch-geometric) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch-geometric) (3.1.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch-geometric) (2.2.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch-geometric) (3.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch) (77.0.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from pytorch-lightning) (1.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from pytorch-lightning) (24.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from pytorch-lightning) (0.14.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp->torch-geometric) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp->torch-geometric) (1.18.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from jinja2->torch-geometric) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric torch torchvision pytorch-lightning requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35bbe4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-lightning==2.5.1 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torch>=2.1.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from pytorch-lightning==2.5.1) (2.7.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from pytorch-lightning==2.5.1) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from pytorch-lightning==2.5.1) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (2025.3.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from pytorch-lightning==2.5.1) (1.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from pytorch-lightning==2.5.1) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from pytorch-lightning==2.5.1) (4.12.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from pytorch-lightning==2.5.1) (0.14.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (3.11.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.5.1) (3.10)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch-lightning==2.5.1) (77.0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning==2.5.1) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning==2.5.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning==2.5.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning==2.5.1) (3.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning==2.5.1) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from torchmetrics>=0.7.0->pytorch-lightning==2.5.1) (2.2.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning==2.5.1) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hadnesreenath\\documents\\project\\vpeleaderboard\\myenv\\lib\\site-packages (from jinja2->torch>=2.1.0->pytorch-lightning==2.5.1) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning==2.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a097d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from the URL:\n",
      "{\n",
      "    \"node_type\": {\n",
      "        \"biological_process\": 0,\n",
      "        \"gene/protein\": 1,\n",
      "        \"disease\": 2,\n",
      "        \"effect/phenotype\": 3,\n",
      "        \"anatomy\": 4,\n",
      "        \"molecular_function\": 5,\n",
      "        \"drug\": 6,\n",
      "        \"cellular_component\": 7,\n",
      "        \"pathway\": 8,\n",
      "        \"exposure\": 9\n",
      "    },\n",
      "    \"relation_type\": {\n",
      "        \"expression present\": 0,\n",
      "        \"synergistic interaction\": 1,\n",
      "        \"interacts with\": 2,\n",
      "        \"ppi\": 3,\n",
      "        \"phenotype present\": 4,\n",
      "        \"parent-child\": 5,\n",
      "        \"associated with\": 6,\n",
      "        \"side effect\": 7,\n",
      "        \"contraindication\": 8,\n",
      "        \"expression absent\": 9,\n",
      "        \"target\": 10,\n",
      "        \"indication\": 11,\n",
      "        \"enzyme\": 12,\n",
      "        \"transporter\": 13,\n",
      "        \"off-label use\": 14,\n",
      "        \"linked to\": 15,\n",
      "        \"phenotype absent\": 16,\n",
      "        \"carrier\": 17\n",
      "    },\n",
      "    \"emb_dim\": {\n",
      "        \"biological_process\": 768,\n",
      "        \"cellular_component\": 768,\n",
      "        \"disease\": 768,\n",
      "        \"drug\": 512,\n",
      "        \"molecular_function\": 768,\n",
      "        \"gene/protein\": 2560\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "data_url = \"https://raw.githubusercontent.com/RyanWangZf/BioBridge/main/data/BindData/data_config.json\"\n",
    "response = requests.get(data_url)\n",
    "if response.status_code == 200:\n",
    "    print(\"Data from the URL:\")\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(f\"Failed to fetch data. HTTP Status Code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fda8234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "'''\n",
    "This module contains the BioBridgeDataModule class, which is a subclass of LightningDataModule.\n",
    "It loads the BioBridge dataset (a subset of PrimeKG) and stores the data in a format that can \n",
    "be accessed outside of the Jupyter notebook.\n",
    "'''\n",
    "\n",
    "from typing import Any, Dict, Optional\n",
    "import torch\n",
    "import torch_geometric.data as geom_data\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import shutil\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "class BioBridgeDataModule(LightningDataModule):\n",
    "    \"\"\"`LightningDataModule` for the BioBridge dataset.\n",
    "    \n",
    "    The BioBridge dataset is a subset of PrimeKG, enriched with multi-modal features\n",
    "    and node embeddings, used for tasks such as biomedical entity prediction, cross-modal retrieval, \n",
    "    and multimodal question answering.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = \"/tmp/biobridge\",  # Path to save the data\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = 0,\n",
    "        pin_memory: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize a `BioBridgeDataModule`.\n",
    "\n",
    "        Args:\n",
    "            data_dir: The data directory to download and store the dataset.\n",
    "            batch_size: The batch size for data loading.\n",
    "            num_workers: Number of workers for data loading.\n",
    "            pin_memory: Whether to pin memory during data loading.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.data = None\n",
    "        self.batch_size_per_device = batch_size\n",
    "        self.data_dir = data_dir\n",
    "    # def prepare_data(self) -> None:\n",
    "    #     \"\"\"\n",
    "    #     Download and prepare the BioBridge data.\n",
    "    #     This will be called on a single process to download and preprocess the data.\n",
    "    #     \"\"\"\n",
    "    #     if not os.path.exists(self.data_dir):\n",
    "    #             os.makedirs(self.data_dir)\n",
    "\n",
    "    #         # Download the JSON file\n",
    "    #     data_url = \"https://raw.githubusercontent.com/RyanWangZf/BioBridge/main/data/BindData/data_config.json\"\n",
    "    #     json_path = os.path.join(self.data_dir, \"data_config.json\")\n",
    "    #     if not os.path.exists(json_path):\n",
    "    #         print(\"Downloading BioBridge dataset...\")\n",
    "    #         with requests.get(data_url, stream=True) as r:\n",
    "    #             with open(json_path, \"wb\") as f:\n",
    "    #                 shutil.copyfileobj(r.raw, f)\n",
    "    #         print(f\"Dataset downloaded to {json_path}.\")\n",
    "\n",
    "    #     # Generate or download the .npy files\n",
    "    #     node_features_path = os.path.join(self.data_dir, \"node_features.npy\")\n",
    "    #     edge_index_path = os.path.join(self.data_dir, \"edges.npy\")\n",
    "    #     if not os.path.exists(node_features_path) or not os.path.exists(edge_index_path):\n",
    "    #         print(\"Generating or downloading .npy files...\")\n",
    "    #     # Add logic to generate or download the .npy files\n",
    "    #     # Example: Parse the JSON and create .npy files\n",
    "    #     raise NotImplementedError(\"Logic to generate .npy files is not implemented.\")\n",
    "\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        \"\"\"\n",
    "        Download and prepare the BioBridge data.\n",
    "        This will be called on a single process to download and preprocess the data.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.data_dir):\n",
    "            os.makedirs(self.data_dir)\n",
    "\n",
    "        # Download the JSON file\n",
    "        data_url = \"https://raw.githubusercontent.com/RyanWangZf/BioBridge/main/data/BindData/data_config.json\"\n",
    "        json_path = os.path.join(self.data_dir, \"data_config.json\")\n",
    "        if not os.path.exists(json_path):\n",
    "            print(\"Downloading BioBridge dataset...\")\n",
    "            with requests.get(data_url, stream=True) as r:\n",
    "                with open(json_path, \"wb\") as f:\n",
    "                    shutil.copyfileobj(r.raw, f)\n",
    "            print(f\"Dataset downloaded to {json_path}.\")\n",
    "\n",
    "        # Check if the file is compressed\n",
    "        if json_path.endswith(\".gz\"):\n",
    "            print(\"Decompressing the JSON file...\")\n",
    "            decompressed_path = json_path[:-3]  # Remove the .gz extension\n",
    "            with gzip.open(json_path, \"rb\") as f_in:\n",
    "                with open(decompressed_path, \"wb\") as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "            json_path = decompressed_path\n",
    "\n",
    "        # Generate the .npy files\n",
    "        node_features_path = os.path.join(self.data_dir, \"node_features.npy\")\n",
    "        edge_index_path = os.path.join(self.data_dir, \"edges.npy\")\n",
    "        if not os.path.exists(node_features_path) or not os.path.exists(edge_index_path):\n",
    "            print(\"Generating .npy files from JSON...\")\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data_config = json.load(f)\n",
    "\n",
    "            # Example: Extract node features and edges from the JSON\n",
    "            node_features = data_config[\"node_features\"]  # Replace with the actual key\n",
    "            edge_index = data_config[\"edges\"]  # Replace with the actual key\n",
    "\n",
    "            # Save as .npy files\n",
    "            np.save(node_features_path, np.array(node_features))\n",
    "            np.save(edge_index_path, np.array(edge_index))\n",
    "            print(f\"Generated .npy files: {node_features_path}, {edge_index_path}\")\n",
    "    def load_biobridge_data(self, data_path: str):\n",
    "        \"\"\"\n",
    "        Load and process the BioBridge data (subset of PrimeKG) into PyTorch Geometric format.\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path where BioBridge data is stored.\n",
    "        \n",
    "        Returns:\n",
    "            PyTorch Geometric data object.\n",
    "        \"\"\"\n",
    "        # Example loading node features and edge list from .npy files\n",
    "        node_features = np.load(os.path.join(data_path, \"node_features.npy\"))  # Node features\n",
    "        edge_index = np.load(os.path.join(data_path, \"edges.npy\"))  # Edge list (edge_index)\n",
    "\n",
    "        # Convert data to PyTorch Geometric Data format\n",
    "        data = geom_data.Data(x=torch.tensor(node_features, dtype=torch.float),\n",
    "                               edge_index=torch.tensor(edge_index, dtype=torch.long))\n",
    "\n",
    "        return data\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Load data and set up training, validation, and test sets.\n",
    "        This is called on every process in DDP (Distributed Data Parallel) training.\n",
    "        \"\"\"\n",
    "        pass  # This function can be extended if needed for train/test splits.\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader[Any]:\n",
    "        \"\"\"\n",
    "        Create and return the train dataloader.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            DataLoader: The train dataloader.\n",
    "        \"\"\"\n",
    "        return geom_data.DataLoader(self.data,\n",
    "                                    batch_size=self.batch_size_per_device,\n",
    "                                    num_workers=self.hparams.num_workers,\n",
    "                                    shuffle=True)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader[Any]:\n",
    "        \"\"\"\n",
    "        Create and return the validation dataloader.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            DataLoader: The validation dataloader.\n",
    "        \"\"\"\n",
    "        return geom_data.DataLoader(self.data,\n",
    "                                    batch_size=self.batch_size_per_device,\n",
    "                                    num_workers=self.hparams.num_workers,\n",
    "                                    shuffle=False)\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader[Any]:\n",
    "        \"\"\"\n",
    "        Create and return the test dataloader.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            DataLoader: The test dataloader.\n",
    "        \"\"\"\n",
    "        return geom_data.DataLoader(self.data,\n",
    "                                    batch_size=self.batch_size_per_device,\n",
    "                                    num_workers=self.hparams.num_workers,\n",
    "                                    shuffle=False)\n",
    "\n",
    "    def teardown(self, stage: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Cleanup after training, validation, or testing.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def state_dict(self) -> Dict[Any, Any]:\n",
    "        \"\"\"\n",
    "        Called when saving a checkpoint. Implement to generate and save the datamodule state.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            Dict: A dictionary containing the datamodule state.\n",
    "        \"\"\"\n",
    "        return {}\n",
    "\n",
    "    def load_state_dict(self, state_dict: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Called when loading a checkpoint. Implement to reload datamodule state.\n",
    "\n",
    "        Args:\n",
    "            state_dict: The datamodule state returned by `self.state_dict()`.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1ad97ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating .npy files from JSON...\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the BioBridge data\u001b[39;00m\n\u001b[32m      2\u001b[39m data_module = BioBridgeDataModule(data_dir=\u001b[33m\"\u001b[39m\u001b[33m/tmp/biobridge\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdata_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure the data is downloaded\u001b[39;00m\n\u001b[32m      4\u001b[39m data = data_module.load_biobridge_data(data_module.data_dir)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Display the number of nodes and edges\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 113\u001b[39m, in \u001b[36mBioBridgeDataModule.prepare_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGenerating .npy files from JSON...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_path, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     data_config = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Example: Extract node features and edges from the JSON\u001b[39;00m\n\u001b[32m    116\u001b[39m node_features = data_config[\u001b[33m\"\u001b[39m\u001b[33mnode_features\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# Replace with the actual key\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    294\u001b[39m         \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m         parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:322\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Load the BioBridge data\n",
    "data_module = BioBridgeDataModule(data_dir=\"/tmp/biobridge\")\n",
    "data_module.prepare_data()  # Ensure the data is downloaded\n",
    "data = data_module.load_biobridge_data(data_module.data_dir)\n",
    "\n",
    "# Display the number of nodes and edges\n",
    "print(f\"Number of nodes: {data.x.size(0)}\")\n",
    "print(f\"Number of edges: {data.edge_index.size(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1121b370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60e862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
